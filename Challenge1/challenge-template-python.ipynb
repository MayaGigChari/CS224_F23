{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40d4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ba6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/ancestry_train.data\", sep = \" \", header=None).values\n",
    "y_train = pd.read_csv(\"data/ancestry_train.solution\", sep = \" \", header=None).values\n",
    "\n",
    "X_test = pd.read_csv(\"data/ancestry_test.data\", sep = \" \", header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df617cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa095d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.198, 0.75 , 0.052],\n",
       "       [0.858, 0.142, 0.   ],\n",
       "       [0.761, 0.237, 0.001],\n",
       "       ...,\n",
       "       [0.001, 0.183, 0.817],\n",
       "       [0.016, 0.591, 0.393],\n",
       "       [0.   , 0.007, 0.993]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f57150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 2, 1, 1],\n",
       "       [0, 0, 2, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de22ea6",
   "metadata": {},
   "source": [
    "# cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6691a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_true, y_hat):\n",
    "    mse = -np.log10(np.mean((y_true-y_hat)**2)+1e-5)\n",
    "    return(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### MODEL 1: SIMPLE RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcbbe598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a757ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Random Forest classifier\n",
    "clf = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(y_pred)\n",
    "cost(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279cd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(X_test)\n",
    "pd.DataFrame(y_test).to_csv(f\"predictions.csv\", sep = \" \", header = None, index = None)\n",
    "os.system(\"zip -r predictions.zip predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb34a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.68791317e-51 0.00000000e+00 1.00000000e+00]\n",
      " [4.78632874e-74 0.00000000e+00 1.00000000e+00]\n",
      " [1.52856970e-66 0.00000000e+00 1.00000000e+00]\n",
      " ...\n",
      " [1.06710770e-78 1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.69328467e-55 1.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#another attempt: GLM\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have SNP data (X_snp) and ancestry labels (y_labels)\n",
    "\n",
    "# Initialize GMM\n",
    "num_ancestries = 3  # Update this based on the number of ancestries you want to identify\n",
    "gmm = GaussianMixture(n_components=num_ancestries, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gmm.fit(X_train)\n",
    "\n",
    "# Assign labels to individuals based on highest probability cluster\n",
    "predicted_labels = gmm.predict(X_train)\n",
    "\n",
    "# For new individuals without labels:\n",
    "# Assuming new_data contains SNP data of new individuals\n",
    "predicted_new_labels = gmm.predict(X_test)\n",
    "\n",
    "# Calculate ancestry proportions for each individual\n",
    "probs = gmm.predict_proba(X_train)\n",
    "# probs contains the probability of each individual belonging to each ancestry\n",
    "\n",
    "print(probs)\n",
    "\n",
    "# Assess performance (if true labels are available)\n",
    "#accuracy = np.mean(predicted_labels == y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce841508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another attempt: independent logistic regression. this scores well (2.4). best so far. \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize three linear regression models for each ancestral group\n",
    "linreg_ancestry_1 = LinearRegression()\n",
    "linreg_ancestry_2 = LinearRegression()\n",
    "linreg_ancestry_3 = LinearRegression()\n",
    "\n",
    "# Train each model separately on the corresponding column of y_labels\n",
    "linreg_ancestry_1.fit(X_train, y_train[:, 0])  # First column represents ancestry 1\n",
    "linreg_ancestry_2.fit(X_train, y_train[:, 1])  # Second column represents ancestry 2\n",
    "linreg_ancestry_3.fit(X_train, y_train[:, 2])  # Third column represents ancestry 3\n",
    "\n",
    "# Predict values for each ancestral group for the test set\n",
    "y_pred_ancestry_1 = linreg_ancestry_1.predict(X_test)\n",
    "y_pred_ancestry_2 = linreg_ancestry_2.predict(X_test)\n",
    "y_pred_ancestry_3 = linreg_ancestry_3.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ae534a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_ancestry_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((\u001b[43my_pred_ancestry_1\u001b[49m, y_pred_ancestry_2, y_pred_ancestry_3))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Normalize along each row to ensure each row sums to 1\u001b[39;00m\n\u001b[1;32m      5\u001b[0m all_predictions[all_predictions \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_ancestry_1' is not defined"
     ]
    }
   ],
   "source": [
    "all_predictions = np.column_stack((y_pred_ancestry_1, y_pred_ancestry_2, y_pred_ancestry_3))\n",
    "\n",
    "# Normalize along each row to ensure each row sums to 1\n",
    "\n",
    "all_predictions[all_predictions < 0] = 0\n",
    "\n",
    "normalized_predictions = all_predictions / np.sum(all_predictions, axis=1, keepdims=True)\n",
    "\n",
    "print(normalized_predictions)\n",
    "\n",
    "pd.DataFrame(normalized_predictions).to_csv(f\"predictions.csv\", sep = \" \", header = None, index = None)\n",
    "os.system(\"zip -r predictions.zip predictions.csv\")\n",
    "\n",
    "#plt.scatter (X_test, y_pred_ancestry_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0188a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.50018079 0.49981921]\n",
      " [0.9926543  0.0073457  0.        ]\n",
      " [0.         0.         1.        ]\n",
      " ...\n",
      " [0.02971191 0.47441637 0.49587171]\n",
      " [0.02313964 0.         0.97686036]\n",
      " [0.04434458 0.10199848 0.85365694]]\n",
      "updating: predictions.csv (deflated 54%)\n",
      "[[0.         0.540707   0.54031613]\n",
      " [1.01392287 0.00750309 0.        ]\n",
      " [0.         0.         1.09374057]\n",
      " ...\n",
      " [0.0297116  0.47441147 0.49586658]\n",
      " [0.02375787 0.         1.00295937]\n",
      " [0.04434195 0.10199243 0.85360628]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#this is the same relatively as above, performs a bit worse. \n",
    "\n",
    "# Assuming X_train contains SNP data and y_train contains proportions of ancestries A, B, C\n",
    "\n",
    "# Initialize multivariate multiple regression model\n",
    "multivariate_regression = LinearRegression()\n",
    "\n",
    "# Fit the model with SNP data to predict proportions of ancestries A, B, C\n",
    "multivariate_regression.fit(X_train, y_train)  # y_train should contain proportions of A, B, C as columns\n",
    "\n",
    "# Predict proportions for test SNP data\n",
    "predictions = multivariate_regression.predict(X_test)\n",
    "\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "\n",
    "normalized_predictions = predictions / np.sum(predictions, axis=1, keepdims=True)\n",
    "\n",
    "print(normalized_predictions)\n",
    "\n",
    "pd.DataFrame(normalized_predictions).to_csv(f\"predictions.csv\", sep = \" \", header = None, index = None)\n",
    "os.system(\"zip -r predictions.zip predictions.csv\")\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf4cfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=TweedieRegressor(alpha=0.5, link=&#x27;identity&#x27;,\n",
       "                                                power=0))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=TweedieRegressor(alpha=0.5, link=&#x27;identity&#x27;,\n",
       "                                                power=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: TweedieRegressor</label><div class=\"sk-toggleable__content\"><pre>TweedieRegressor(alpha=0.5, link=&#x27;identity&#x27;, power=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TweedieRegressor</label><div class=\"sk-toggleable__content\"><pre>TweedieRegressor(alpha=0.5, link=&#x27;identity&#x27;, power=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=TweedieRegressor(alpha=0.5, link='identity',\n",
       "                                                power=0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this gettst a score of 2.8 \n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming X_train contains SNP data and y_train contains proportions of ancestries A, B, C in three columns\n",
    "\n",
    "# Initialize Tweedie regression model with appropriate settings\n",
    "tweedie_regression = TweedieRegressor(power=0, link='identity', alpha=0.5)\n",
    "\n",
    "# Wrap the model with MultiOutputRegressor for multi-output regression\n",
    "multi_output_model = MultiOutputRegressor(tweedie_regression)\n",
    "\n",
    "# Fit the model with SNP data to predict proportions of ancestries A, B, C\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48329432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: predictions.csv (deflated 54%)\n",
      "[[0.         0.4816134  0.5183866 ]\n",
      " [0.97679839 0.01478855 0.00841306]\n",
      " [0.         0.00299924 0.99700076]\n",
      " ...\n",
      " [0.04435038 0.43797064 0.51767898]\n",
      " [0.00212866 0.02028689 0.97758444]\n",
      " [0.03895111 0.12682317 0.83422572]]\n"
     ]
    }
   ],
   "source": [
    "predictions = multi_output_model.predict(X_test)\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "# Normalize predictions for each row (across the three columns)\n",
    "normalized_predictions = predictions / np.sum(predictions, axis=1, keepdims=True)\n",
    "\n",
    "pd.DataFrame(normalized_predictions).to_csv(f\"predictions.csv\", sep = \" \", header = None, index = None)\n",
    "os.system(\"zip -r predictions.zip predictions.csv\")\n",
    "\n",
    "print(normalized_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4e3325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489b6cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.39594929   1.09686919  -2.90580617]\n",
      " [  1.7981697   -1.80168823  -7.7551872 ]\n",
      " [  1.16062398  -1.16808911  -6.60380831]\n",
      " ...\n",
      " [ -7.19786233  -1.49896121   1.49395977]\n",
      " [ -4.10260007   0.36689711  -0.4345928 ]\n",
      " [-13.81550956  -4.95233576   4.95220542]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#attempt 11/16: try to make all labels > 0 before I make predictions \n",
    "y_train_clipped = np.clip(y_train, 0.000001, 0.999999)  # Avoids exact 0 or 1\n",
    "def apply_log(val):\n",
    "    return np.log(val / (1 - val))\n",
    "\n",
    "# Apply the function to all columns\n",
    "y_train = apply_log(y_train_clipped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9cdbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#this doesn't work at all. \n",
    "# Initialize three linear regression models for each ancestral group\n",
    "linreg_ancestry_1 = LinearRegression()\n",
    "linreg_ancestry_2 = LinearRegression()\n",
    "linreg_ancestry_3 = LinearRegression()\n",
    "\n",
    "# Train each model separately on the corresponding column of y_labels\n",
    "linreg_ancestry_1.fit(X_train, y_train[:, 0])  # First column represents ancestry 1\n",
    "linreg_ancestry_2.fit(X_train, y_train[:, 1])  # Second column represents ancestry 2\n",
    "linreg_ancestry_3.fit(X_train, y_train[:, 2])  # Third column represents ancestry 3\n",
    "\n",
    "# Predict values for each ancestral group for the test set\n",
    "y_pred_ancestry_1 = linreg_ancestry_1.predict(X_test)\n",
    "y_pred_ancestry_2 = linreg_ancestry_2.predict(X_test)\n",
    "y_pred_ancestry_3 = linreg_ancestry_3.predict(X_test)\n",
    "\n",
    "all_predictions = np.column_stack((y_pred_ancestry_1, y_pred_ancestry_2, y_pred_ancestry_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b90dcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.13620897e-03 5.42451250e-01 8.78146134e-01]\n",
      " [9.80941114e-01 1.78404116e-02 9.14517930e-06]\n",
      " [5.05674566e-06 1.95833512e-02 9.88957387e-01]\n",
      " ...\n",
      " [2.42721613e-03 4.26680888e-01 7.16401028e-01]\n",
      " [2.37133835e-05 1.96596388e-02 9.50705984e-01]\n",
      " [9.27706788e-05 4.20877985e-02 8.98895293e-01]]\n"
     ]
    }
   ],
   "source": [
    "def return_toscale(y):\n",
    "    return 1 / (np.exp(-y) + 1)\n",
    "\n",
    "all_predictions = return_toscale(all_predictions)\n",
    "\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540225ae",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'reduced_snp_data' contains the transformed data from PCA\n",
    "\n",
    "# Plotting the first two principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_snp_data[:, 0], reduced_snp_data[:, 1], alpha=0.5)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Visualization of Principal Components')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c9558",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa4a7319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401067369385945"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = np.ones((y_train.shape[0], y_train.shape[1])) * (1/3)\n",
    "cost(y_train, base)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7760b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.ones((X_test.shape[0], y_train.shape[1])) * (1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7ee63",
   "metadata": {},
   "source": [
    "# save and zip the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e6ff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: predictions.csv (deflated 100%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).to_csv(f\"predictions.csv\", sep = \" \", header = None, index = None)\n",
    "os.system(\"zip -r predictions.zip predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49a899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32fb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b83d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407dc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0f503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90203cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3873e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
